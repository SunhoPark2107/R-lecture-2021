모델링 및 해석 단계)

1) 일단 모델링 할 데이터 가공. (filter, mutate, groupby summarise 등등)

2) 모델링. 

선형회귀 : model <- lm(y ~ x, data = 데이터 이름)
다중회귀 : model <- lm(y ~ x + u, data = 데이터 이름)

3) 데이터 그래프 그려 보고(산점도), 그 위에 모델링 데이터 그래프 얹어 보기.

(선형회귀)
plot(데이터이름)
abline(model, col = "", lwd = 선 너비 숫자로 지정.)

ggplot쓰면 jitter사용 및 한줄로 코드 정리 가능.

ggplot(데이터 이름, aes(x, y)) +
geom_point(position = "jitter", color = "") +
geom_abline(intercept=coef(model)[1], slope = coef(moel)[2], color = "", size = 라인사이즈)

coef(m) 하면 y절편 intercept나오고, 기울기 나옴.(x변수에 할당되었으므로 x좌표 밑으로 나온다.) 위에 abline에서 coef벡터값을 통해서 y절편과 기울기를 지정해 주고 있는 것.

(다중회귀)
다중회귀 그래프 그리려면 scatterplot3d 라이브러리가 필요하다.

s <- scatterplot3d(x, u, y, ...)
scatterplot3d에서 ...에는 그냥 , 로 이어서 pch, type, color 써주면 된다.

s$plane3d(model)
s에 저장해 둔 3d그래프에 모델링 그래프 그리기. 모델링 그래프는 박스에 면으로 나온다.


4) 잔차랑 평균제곱 오차를 구해 본다.
잔차는 우리가 예측한 모델이 실제와 얼마나 차이가 있는가, 근데 아마 데이터가 많아지면 잔차값도 많아져서 보기 힘들기 때문에 잔차를 볼 일은 별로 없을듯? 아니면 랜덤한 샘플을 뽑아서 잔차를 볼 수는 있겠다.

우리가 만든 모델이 예측하는 값들 보기. x(선형) 또는 x + u(다중)의 개수만큼 뽑혀나온다.
fitted(model)

우리가 만든 모델과 실제값(y)과의 차이들 보기. x(선형) 또는 x + u(다중)의 개수만큼 뽑혀나온다.
residuals(model)

평균제곱오차(mse)보기. 모델링한 결과와 실제 데이터 간에 차이를 하나의 수치로 볼 수 있다.

deviance(model) / length(y)

5) 새로운 데이터가 들어왔을 때 우리가 만든 모델이 예측을 어떻게 해주나 함 보기.(걍 보는거임... 사실 모델 검증부터 하고 맨 마지막에 하는게 맞지 않나 싶네?)

(선형회귀)
nx = c(1, 2)
new_data <- data.frame(x = nx)

predict(model, new_data)

주의할점 : x가 변수가 하나밖에 없어서 vector긴 한데, predict에 사용할 데이터는 반드시 data.frame형태이므로 실제 데이터가 벡터라도 반드시 데이터 프레임 형식으로 지정해 주도록 한다.

(다중회귀)
nx = c(1, 2)
nu = c(3, 4)
new_data <- data.frame(x = nx, u = nu)

predict(model, new_data)

6) 모델 검증의 시간~

6-1) summary(model)
summary 모델을 통해서 봐야 하는 건 딱 세가지임.
첫번째 => 각 변수별로 정리되어 있는 Pr값을 확인해서 모델이 제시하는 각각의 독립변수와 종속변수간 관계가 유의미한지 확인해야 함.(유의미하지 않다면 빼는게 나으니까!) 
두번째 => Adjusted R-squared 값을 확인해야 함. 결정계수 또는 설명계수인데, 데이터마다 성격이 천차만별이라서 얼마 이상이면 좋은 데이터!라고 딱 정해진 것은 없음. 그냥 "이 모델이 얼마나 말이 되나" 요정도로 생각하면 될 것 같음.
세 번째 => 모델 자체의 p-value값을 봐 줘야 함. 모델 자체의 p-value값이 0.05(혹은 더 작아질 수도 있다) 보다 크다면 이 모델은 틀린 모델이라고 할 수 있음.

6-2) 모델 진단 그래프 그려보기(4종이 출력된다.)

par(mfrow = c(2,2))    이건 그냥 그래프 4종이 출력 되는 걸 한 페이지에 보고 싶어서 하는 것이다. 중요한건아님.
flot(model)
par(mfrow = c(1,1))     바꾼 설정 원래대로 돌려야 함. 안그러면 계속 1/4쪼가리로 나온다.

간단히, 그냥 plot(model)하면 된다.

그러면 나오는 그래프가 4개가 있다. 4가지의 그래프는 다음과 같다.

첫번째 그래프(Residual vs Fitted plot) : x축이 모델 예측값, y축이 잔차인 그래프이다. 선형회귀에서는 선의 기울기가 0 즉, 일직선이면 좋은거라고 한다. 왜 좋은지는 모르겠다.

두번째 그래프(Normal Q-Q plot) : 잔차가 정규분포를 따르는지를 확인하는 그래프이다. 잔차가 정규분포를 따르면 왜 좋은지는 모르겠다.

세 번째 그래프(Scale-Location plot) : x축에는 모델 예측값, y축은 표준화 잔차인 그래프로, 빨간색 추세선이 0인 직선일수록 좋은 것이라고 한다. 0에서 멀리 떨어질수록 표준화 잔차가 크고 회귀 직선이 적합하지 못하다는 의미이며, 멀리 떨어진 값들은 이상치.

네 번째 그래프(Residuals vs Leverage plot) : 쿡의 거리가 표시되어 있는 그래프(?). 회귀 직선의 모양, 즉 기울기나 절편 등에 크게 영향을 미치는 점들을 찾는 방법이다. (예를 들어 c(1, 2, 4, 6, 87, 2, 1 ))이런 관측치의 경우 87은 회귀직선에 영향을 크게 미치게 된다. 이런 애들이 많으면 많을수록 안좋겠지...? // 점들이 한 쪽에 몰려 있을 수록 좋은 것이며, 쿡의 거리가 0.5 이상인 빨간 점선을 벗어나는 점은 무시할 수 있는 예측치를 크게 벗어난 관측값이라고 할 수 있다.


6-3)차수를 높여 보기. (해도 그만 안 해도 그만. 선형회귀에만 사용되는 듯 하다.)

차수를 높였을 때 모델의 정확도도 올라가고 설명도도 올라가는 데이터가 있다.
우리가 써 봤던 데이터들 중에는 women데이터가 2차식으로 썼을 때 p값도 줄어들고 R-squared값도 증가하였다. 따라서 차수를 높여 봐서 더 나은 애가 있다면 그걸 써도 괜찮겠다. 하지만 이건 필수는 아님.

똑같은 코드를 만들 차수의 개수만큼 써야 하므로 for loop문을 사용하면 편하다.

colors <- c('red', 'purple', 'dark orange', 'blue')
plot(g1)

x <- seq(시작범위, 끝범위, length.out = 간격(단위)염두에 두고 지정하세용 보통 끝-시작 + 1) 
for (i in 1:4) {
    m <- lm(Height_cm~poly(Father_cm, i), data = g1)
    assign(paste('m', i, sep = '.'), m)
    y <- predict(m, data.frame(Father_cm = x))
    lines(x, y, col = colors[i], lwd = 2)
}



여기부터는 독립변수가 여러 개인 다중회귀에만 사용되는 기법들.

1) 다중공선성 확인(독립 변수 간에 강한 상관관계가 나타나는 경우 결과도출에 방해됨.)
값이 0.9 이상이면 다중공선성을 의심.

cor(데이터명[2:n]) <- 다중공선성 확인할 독립변수 있는 열만큼 벡터로 지정하기.

vif 계산 (값이 10 이상이면 다중공선성을 의심.)
vif(model)


2) 모델 품질평가(또는 성능평가) - 어떤 독립변수를 빼고 넣어야 좋은 모델인지 알려주는 함수를 돌려보기.
model1 <- lm(y ~ ., data = 데이터명)     => 여기에서 . 은 모든 독립변수를 넣겠다는 것.
model2 <- lm(y ~ x + u, data = 데이터명)  => 일부 독립변수만을 포함한 모델.

AIC(model1, model2) => 각 모델의 점수를 알려 줌. 값이 적을수록 좋은 모델이라는 뜻.

모델을 내가 하나하나 지정하지 않고도, 전체 경우의 수를 통하여 뭐가 젤 좋은지 찾아 줄 수 있다.

step(model1, direction = "backward")

=> 이렇게 하면, 모든 독립변수를 포함한 모델 model1에서 독립변수를 빼 가면서 모든 경우의 수의 AIC값을 찾아 준다.

반대로 찾는 방법도 있다.

model3 <-lm(y ~ 1, data = 데이터 명)
step(model3, direction = "forward",
scope = x + u + ... + z)

이렇게 해 주면 scope 범위 안에 있는 변수들을 가지고 추가해 가면서 모든 조합들의 AIC값을 찾아 준다.


s