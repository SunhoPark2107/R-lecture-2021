data <- as.factor(data)

data <- factor(data) 

왜 as.안써도 되는거지??? => 위에거는 범주형으로 변경하여 저장, 아래 거는 범주형 변수를 생성하여 저장.


모델 선택에 필수적인 것

재현률 => 0, 1 두 가지의 결과 중 어느 한 가지의 결과에 더 가중치를 두어야 하는 것.
(정확도보다 중요한 것.)

ex) 배심원 => 무죄 추정의 원칙. 무고한 사람이 유죄 판결을 받는 것이 가장 안 좋은 결과이므로 무죄임에 더 가중치를 두어 판단해야 한다.
의사 => 암 진단을 하는 경우, 암이 아닌 사람을 암이라고 진단하는 것보다 암인 사람을 암이 아닌 것으로 진단했을 때 피해가 더 크므로, 과잉진료가 되더라도 암이 의심되는 경우 암이 맞다는 것에 더 가중치를 두어 판단해야 한다.

MNIST 손글씨 변환기

0 1 2 3 4 5 6 7 8 9

분류기: 어떤 숫자인가?

그 숫자가 7이냐? => "아니다"라는 대답은 90%의 정확률. (정확도의 맹점 => 아무런 의미가 없는 정확률.)

암 진단의 경우, 1000명이 진단받으면 2-3명도 되지 않을 것. 이 때 모두 암이 아니라고 진단한다면 99%가 넘는 정확률을 보이지만, 아무런 의미도 없는 정확률이 된다.

교차 검증
샘플링을 통해 추출한 데이터 셋에 따라 모델이 우연히 높은 정확률을 가질 수도 있고 그 반대일 수도 있음.
=> 따라서 데이터를 쪼개 각각 여러 번 반복하여 평균을 취하여 우연을 줄이고 통계적 신뢰성을 높이는 것.


k-겹(k-fold) 교차 검증
데이터를 k개의 부분 집합으로 나누고, 하나씩 테스트 데이터 셋으로 만들면서 평균을 찾음.
이후에 모델의 정확도도 평균냄.


i = 1
i : i*q (1:30)

i = 2
(i-1)*q+1

sort(resam) 함수
a <- class()

객체지향

() 안에 method가 들어간다.
a.sort(method)

caret은 딥러닝 위한 라이브러리이므로 객체지향적으로 봐야 한다.(???)


모델 검증 및 하이퍼 파라미터 검증(fine tuning)은 최소한 각 10번씩 해서 최적 모델/최적 변수를 선택해야 한다.





