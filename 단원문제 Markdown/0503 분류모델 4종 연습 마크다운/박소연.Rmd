---
title: "4 Models for classification"
author: "Soyeon Park"
date: '2021 5 3 '
output: html_document
---
### ucla 데이터 받아오기

```{r}
ucla <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
str(ucla)  # 4개의 변수, 400개의 데이터
ucla$admit <- factor(ucla$admit) # int로 되어 있는 admit 변수속성 factor로 변경하여 저장하기.
```

4가지 모델로 예측 및 평가할 것.
오늘 배운 모델 => rpart(결정트리), randomForest(랜덤포레스트), svm(support vector machine), knn(k-nearest neighbor)

### train_set, test_set 만들기.
```{r}
set.seed(2021)    # 샘플 뽑을 경우의 번호(?)는 2021로 임의 고정해두겠음.
library(caret)    # createDataPartition 포함 패키지.
train_index <- createDataPartition(ucla$admit, p=0.8, list = F)
ucla_train <- ucla[train_index, ]
ucla_test <- ucla[-train_index, ]
table(ucla_train$admit)
table(ucla_test$admit)

```



### 결정트리모델 dt_u 생성

```{r}
library(rpart)
dt_u <- rpart(admit ~ ., ucla_train)
```

### dt_u 시각화
```{r}
par(mfrow = c(1,1), xpd = NA)
plot(dt_u)
text(dt_u, use.n = TRUE)
```

### test셋을 통한 결정트리 예측 및 평가
```{r}
pred_dtu <- predict(dt_u, ucla_test, type = "class")
table(pred_dtu, ucla_test$admit)
confusionMatrix(pred_dtu, ucla_test$admit)    # 정확도는 69퍼(0.696)(set.seed(2021) 기준)
```

### 랜덤포레스트 모델 만들고 시각화하고 테스트셋으로 예측하고 평가하기.
```{r}
library(randomForest)
rf_u <- randomForest(admit ~ ., ucla_train)

plot(rf_u)

print(rf_u)

pred_rfu <- predict(rf_u, ucla_test, type ="class")

table(pred_rfu, ucla_test$admit)

confusionMatrix(pred_rfu, ucla_test$admit)    # 랜덤포레스트 모델 정확도는 67퍼(0.671)(set.seed(2021) 기준)
```


### svm 모델

```{r}
library(e1071)     # svm 사용하기 위한 패키지
svm_u <- svm(admit ~ . , ucla_train)

pred_svmu <- predict(svm_u, ucla_test, type = "class")

confusionMatrix(pred_svmu, ucla_test$admit)      # svm 모델 정확도는 67퍼(0.671)(set.seed(2021) 기준)
```

# k-nn모델

```{r}
library(class)      # knn 함수 포함되어 있는 패키지.
knn_u <- knn(ucla_train[, 2:4], ucla_test[, 2:4], ucla_train$admit, k=10)

knn_u
ucla_test$admit

confusionMatrix(knn_u, ucla_test$admit)          # knn 모델 정확도는 63퍼(0.633)(set.seed(2021) 기준)
```
### Wine 데이터 가져와서 가공
```{r}
wine <- read.table('https://raw.githubusercontent.com/SunhoPark2107/R-lecture-2021/main/data/wine.data.txt', sep = ',')
head(wine)

columns <- readLines('https://raw.githubusercontent.com/SunhoPark2107/R-lecture-2021/main/data/wine.name2.txt')
columns

names(wine)               # V1 은 얻고자 하는 결과. 따라서 2번째 열부터 columns의 변수명을 적용하여 줌.

names(wine) [2:14] <- columns
names(wine)

names(wine)[2:14] <- substr(columns, 4, nchar(columns))     # [1] V1 이런 식으로 되어 있으므로 이름만 남기기 위해서 substr함수 사용.
names(wine)
names(wine)[1] <- 'Y'
names(wine)

wine$Y <- factor(wine$Y)
```

### 훈련 셋, 테스트 셋 만들기.
```{r}
set.seed(2021)
trainW_index <- createDataPartition(wine$Y, p = 0.8, list = F)
wine_train <- wine[trainW_index, ]
wine_test <- wine[-trainW_index, ]
```

### 모델 4종 생성
```{r}

dt_w <- rpart(Y ~ . , wine_train)
rf_w <- randomForest(Y ~ ., wine_train)
svm_w <- svm(Y ~ ., wine_train)
knn_w <- knn(wine_train[, 2:14], wine_test[, 2:14], wine_train$Y, k=5)
knn_w
```

### 와인 결정트리 & randomForest시각화
```{r}

par(mfrow = c(1,1), xpd = NA)
plot(dt_w)
text(dt_w, use.n = TRUE)

plot(rf_w)
```


### 모델 3종 예측모델 만들기
```{r}

pred_dtw <- predict(dt_w, wine_test, type = "class")
pred_rfw <- predict(rf_w, wine_test, type = "class")
pred_svmw <- predict(svm_w, wine_test, type = "class")

```

### 모델의 예측값과 실제 관측값 비교하여 보기.
```{r}

pred_dtw
pred_rfw
pred_svmw
knn_w
wine_test$Y
```

### 각 모델의 정확도 확인하여 보기.

```{r}

confusionMatrix(pred_dtw, wine_test$Y)    # 0.912
confusionMatrix(pred_rfw, wine_test$Y)    # 0.971 
confusionMatrix(pred_svmw, wine_test$Y)    # 1
confusionMatrix(knn_w, wine_test$Y)    # 0.706

```

### ucla, wine 하이퍼 매개변수(랜덤포레스트, suport vector machine) 적용하여 보기.

```{r}

u_rf500 <- randomForest(admit ~ ., ucla_train,
                             ntree = 500, nodesize = 4)

u_s_pred <- predict(u_rf500, ucla_test, type = 'class')

confusionMatrix(u_s_pred, ucla_test$admit)

w_rf300 <- randomForest(Y ~ ., wine_train,
                             ntree = 300, nodesize = 4)

w_s_pred <- predict(w_rf300, wine_test, type = 'class')

confusionMatrix(w_s_pred, wine_test$Y)



pred_svm_u100 <- predict(svm_u, ucla_test, type = "class", cost = 100)

pred_svm_w50 <- predict(svm_w, wine_test, type = "class", cost = 50)



u_rf500
w_rf300
table(pred_svm_u100)
table(pred_svm_w50)
```

# 로지스틱 회귀

```{r}
lrw <- glm(Y ~ . , wine_train, family = binomial)
lrw_pred <- predict(lrw, wine_test, type = 'response')
lrw_pred
lrw_pred <- ifelse(lrw_pred > 0.5, 1, 0)
tw <- table(lrw_pred, wine_test$Y)
lrw_acc <- (tw[1,1] + tw[2,2]) / nrow(wine_test)
lrw_acc
```



# 각 모델의 정확도 확인하여 보기.


```{r}
tw <- table(pred_dtw, wine_test$Y) 
dtw_acc <- (tw[1,1] + tw[2,2])/nrow(wine_test)
rw <- table(pred_rfw, wine_test$Y)
rfw_acc <- (rw[1,1] + rw[2,2])/nrow(wine_test)
sw <- table(pred_svmw, wine_test$Y)
sw_acc <- (sw[1,1] + sw[2,2])/nrow(wine_test)
kw <- table(knn_w, wine_test$Y)
kw_acc <- (kw[1,1] + kw[2,2])/nrow(wine_test)

print(paste(dtw_acc, rfw_acc, sw_acc, kw_acc, lrw_acc))
```















